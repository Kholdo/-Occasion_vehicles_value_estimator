{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# FINAL PROJECT - OCCASION VEHICLES PRICE ESTIMATOR\n",
    "___\n",
    "#### MASTER IN DATA SCIENCE - KSCHOOL - 2016/17\n",
    "#### KOLDO PINA ORTIZ\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The aim of the present work is to get a good estimator of the price of a second-hand vehicle, based on the prices of the second-hand market"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Action Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reach our goal, we will follow the the next steps:\n",
    "\n",
    "1. ***Scrape*** website, **motos.net** to obtain the ***data***.\n",
    "2. ***Clean*** the ***data***.\n",
    "2. ***Merge*** some ***data***.\n",
    "3. ***Train*** various models.\n",
    "4. Compare the metrics and choose the model with the best one.\n",
    "5. Create a flask web server with the app."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Scrape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to scrape each website separately.\n",
    "To this end, we have developed two python scripts called ***scraper_motos.py*** and ***scrapers_coches.py***.\n",
    "Both return a dataframe.\n",
    "\n",
    "You can import them to the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%cd scrapers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Call the scraper_motos function to scrape motos.net and create a csv file with the raw data in scraped_data folder\n",
    "#To do that we need to change our path\n",
    "# %cd scrapers\n",
    "# from scraper_motos import scraper_motos\n",
    "# scraper_motos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Start time: 2017-06-13 19:28:56.441707\n",
    "#num_ads 26588\n",
    "#End time: 2017-06-13 22:47:15.427469"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%cd ..\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_motos_raw = pd.read_csv('scraped_data/test/motos_raw_data.csv')\n",
    "df_motos_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_motos_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_motos_raw['color'].fillna('not specified', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert the dataframe to lower case\n",
    "df_motos_raw = df_motos_raw.apply(lambda x: x.astype(str).str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Join the words in the 'model' and 'type' fields with an underscore\n",
    "df_motos_raw['model'] = df_motos_raw['model'].str.replace(' ', '_')\n",
    "df_motos_raw['type'] = df_motos_raw['type'].str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Looking for duplicates\n",
    "df_motos_raw['is_duplicated'] = df_motos_raw.duplicated()\n",
    "duplicates = df_motos_raw['is_duplicated'].sum()\n",
    "print '%d duplicates' %duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Removing duplicates and delete 'is_duplicated' column\n",
    "df_motos_raw = df_motos_raw.loc[df_motos_raw['is_duplicated']==False]\n",
    "df_motos_raw = df_motos_raw.drop('is_duplicated', 1)\n",
    "df_motos_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets investigate column by column the NaNs we have in the dataframe\n",
    "for column in df_motos_raw.columns:\n",
    "    n_nan = df_motos_raw[column]=='nan'\n",
    "    print column + \" %d -- > %f\" %(n_nan.sum(), (n_nan.sum()*1.0)/df_motos_raw.shape[0]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lets investigate the unique values we have in the columns\n",
    "for column in ['city', 'brand', 'model', 'type', 'color', 'year']:\n",
    "    column_uv = df_motos_raw[column].unique()\n",
    "    print column + \" --> \" + \"%d unique values\" %len(sorted(column_uv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#In order to calculate our first metric, we will use the following columns:\n",
    "# \"lon\" and \"lat\" : These are the longitude and latitude of the corresponding city. We will add them later.\n",
    "# \"brand\", \"model\", \"type\", \"year\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculating the longitude and latitude of the cities\n",
    "import geopy\n",
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cities = df_motos_raw['city'].unique()\n",
    "locations_rows = []\n",
    "for city in cities:\n",
    "    location = geolocator.geocode([city], timeout = 15)\n",
    "    locations_rows.append([city, location.latitude, location.longitude])\n",
    "#Save into a csv\n",
    "df_locations = pd.DataFrame(locations_rows, columns = ['city', 'lat', 'lon'])\n",
    "df_locations.to_csv('auxiliary_data/locations_coords.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_locations.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge df_locations with df_motos_raw\n",
    "df_motos_raw_coord = pd.merge(df_motos_raw, df_locations, on = 'city')\n",
    "#Save into a csv\n",
    "df_motos_raw_coord.to_csv('df_motos_raw_coord.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We have created two csv files with a rank for the motos brands and types\n",
    "# called rank_motos_brands.csv and rank_motos_types.csv\n",
    "\n",
    "# With the first one, rank_motos_brands.csv, we are gint to create another  column, with a score to the corresponding brand\n",
    "df_rank_moto_brand = pd.read_csv('rank_moto_brands.csv', sep=';')\n",
    "df_motos_raw_coord_brand = pd.merge(df_motos_raw_coord, df_rank_moto_brand, on = 'brand', how = 'left')\n",
    "#If the brand does not exist, the rank value will be zero\n",
    "#!!OJO, AÃ‘ADIR MARCAS DE MOTOS QUE FALTAN ANTES DE PONER UN CERO!!!!!!!!!!!!!!!!!\n",
    "df_motos_raw_coord_brand.brand_score.fillna(0, inplace=True)\n",
    "# Save into a csv\n",
    "df_motos_raw_coord_brand.to_csv('df_motos_coord_brand.csv', index = False)\n",
    "\n",
    "# With the second one, rank_moto_types.csv, we are going to create another column, with a score to the corresponding type\n",
    "df_rank_moto_type = pd.read_csv('rank_moto_types.csv', sep=';')\n",
    "df_motos_raw_coord_brand_types = pd.merge(df_motos_raw_coord_brand, df_rank_moto_type, on = 'type', how = 'left')\n",
    "#Save into a csv\n",
    "df_motos_raw_coord_brand_types.to_csv('df_motos_raw_coord_brand_type.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_motos_raw_coord_brand_types.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_motos_raw_coord_brand_types.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OK!, so we have a first version of the data we will use to recommend vehicles\n",
    "# df_motos_raw_coord_brand_types\n",
    "# Lets try to calculate the metric only with some fields. We are going to add these distances:\n",
    "# cities distance, brand_distance, type_distance, year_distance\n",
    "# We need to create some functions:\n",
    "\n",
    "def cities_distance(city_lat, city_lon, user_lat, user_lon):\n",
    "    \"\"\"    \n",
    "    :param city_lat: the value in the dataset's lat column to the corresponding city\n",
    "    :param city_lon: the value in the dataset's lon column to the corresponding city\n",
    "    :param user_lat: The corresponding lat value in the location dataset of the city selected by the user\n",
    "    :param user_lon: The corresponding lon value in the location dataset of the city selected by the user\n",
    "    \n",
    "    :return: The value in kilometers of the distance between the two cities.\n",
    "    \n",
    "    Usage of the Vicenty distance\n",
    "    \"\"\"\n",
    "    \n",
    "    from geopy.distance import vincenty\n",
    "    \n",
    "    column_city = (city_lat, city_lon)\n",
    "    user_city = (user_lat, user_lon)\n",
    "    \n",
    "    return (vincenty(column_city, user_city).km)\n",
    "\n",
    "def distance_abs_value(a_value, b_value):\n",
    "    return abs(a_value - b_value)\n",
    "\n",
    "def w_s(city_row, brand_row, type_row, year_row):\n",
    "    import numpy as np\n",
    "    weigth = 100\n",
    "    brand_weight = 40\n",
    "    type_weight = 40\n",
    "    year_weight = 10\n",
    "    city_weight = 10\n",
    "    \n",
    "    params = np.array([city_row, brand_row, type_row, year_row])\n",
    "    weights = np.array([city_weight, brand_weight, type_weight, year_weight])\n",
    "    \n",
    "    num = sum(params * weights) * 1.0\n",
    "    return num/weigth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Example of request of a user\n",
    "user_request = ('leon', 'bmw', 'custom', 2000)\n",
    "\n",
    "# We need to calculate some variables:\n",
    "user_lat = float(df_locations[df_locations['city'] == user_request[0]].lat)\n",
    "user_lon = float(df_locations[df_locations['city'] == user_request[0]].lon)\n",
    "user_brand = int(df_rank_moto_brand[df_rank_moto_brand['brand'] == user_request[1]].brand_score)\n",
    "user_type = int(df_rank_moto_type[df_rank_moto_type['type'] == user_request[2]].type_score)\n",
    "user_year = user_request[3]\n",
    "\n",
    "user_vars = [user_brand, user_type, user_year]\n",
    "score_columns = ['brand_score', 'type_score', 'year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_motos_raw_coord_brand_types['city_metric'] = df_motos_raw_coord_brand_types.apply(lambda row: cities_distance(row['lat'], row['lon'], user_lat, user_lon), axis=1)\n",
    "\n",
    "for i, element in enumerate(['brand', 'type', 'year']):\n",
    "    new_column = element + '_metric'\n",
    "    print new_column, score_columns[i], user_vars[i]\n",
    "    df_motos_raw_coord_brand_types[new_column] = df_motos_raw_coord_brand_types.apply(lambda row: distance_abs_value(int(row[score_columns[i]]), user_vars[i]), axis=1)\n",
    "    \n",
    "#!!! Revisar ranking de motos, falta alguna, por eso aparenden NAN en la columna brand_score al hacer el merge\n",
    "\n",
    "df_motos_raw_coord_brand_types['total_metric_pond'] = df_motos_raw_coord_brand_types.apply(lambda row: w_s(row['city_metric'], row['brand_metric'], row['type_metric'], row['year_metric']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = df_motos_raw_coord_brand_types.sort_values(by = ['total_metric_pond'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "brand_null = df_motos_raw_coord_brand_types[df_motos_raw_coord_brand_types['brand_score'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for element in brand_null.brand.unique():\n",
    "    print element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "params = np.array([2, 4, 10, 2])\n",
    "weights = np.array([10, 40, 40, 10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sum(params * weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
